# Project: My Race Engineer
# File: docker-compose.yml
# Summary: Docker Compose configuration connecting to existing postgres container
#
# SECURITY REQUIREMENTS:
# =====================
# AUTH_SECRET must be set in .env.docker with at least 32 characters.
# Generate a secure secret with: openssl rand -base64 32
#
# Copy .env.docker.example to .env.docker and configure before starting.
# The application will fail to start if AUTH_SECRET is missing or invalid.

services:
  # Next.js application service
  app:
    build:
      context: .
      dockerfile: Dockerfile
      target: development
    container_name: mre-app
    dns:
      - 8.8.8.8
      - 8.8.4.4
      - 1.1.1.1
    dns_search: []
    env_file:
      - .env.docker
    environment:
      # Database connection (connects to existing postgres container)
      DATABASE_URL: postgresql://${POSTGRES_USER:-pacetracer}:${POSTGRES_PASSWORD:-change-me}@mre-postgres:5432/${POSTGRES_DB:-pacetracer}?connection_limit=10&pool_timeout=10
      # Node environment
      NODE_ENV: ${NODE_ENV:-development}
      # Prefer IPv4 over IPv6 for DNS resolution (fixes Alpine Linux IPv6 timeout issues)
      NODE_OPTIONS: ${NODE_OPTIONS:---dns-result-order=ipv4first}
      # Application configuration
      HOST: ${HOST:-0.0.0.0}
      PORT: ${PORT:-3001}
      TZ: ${TZ:-Australia/Sydney}
      APP_URL: ${APP_URL:-http://localhost:3001}
      # Ingestion service URL (internal Docker network)
      INGESTION_SERVICE_URL: ${INGESTION_SERVICE_URL:-http://liverc-ingestion-service:8000}
      # Feature flags (NEXT_PUBLIC_ prefix required for client-side access)
      NEXT_PUBLIC_ENABLE_PRACTICE_DAYS: ${NEXT_PUBLIC_ENABLE_PRACTICE_DAYS:-true}
      # AUTH_SECRET is loaded from .env.docker via env_file directive
      # REQUIRED: Must be at least 32 characters. Generate with: openssl rand -base64 32
      # The application validates AUTH_SECRET at build time and will fail if invalid
    ports:
      - "${APP_PORT:-3001}:3001"
    volumes:
      # Mount source code for hot reload (development)
      - .:/app
      # Exclude node_modules and .next to use container versions
      - /app/node_modules
      - /app/.next
    networks:
      - mre-network
    restart: unless-stopped
    stdin_open: true
    tty: true
    healthcheck:
      test:
        [
          "CMD",
          "wget",
          "--quiet",
          "--tries=1",
          "--spider",
          "http://localhost:3001/api/v1/health",
        ]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    deploy:
      resources:
        limits:
          # Maximum memory allocation for Next.js app (adjust based on available Docker Desktop RAM)
          # Set to 12G to allow maximum usage while leaving room for other containers
          memory: 12G
        reservations:
          # Minimum guaranteed memory
          memory: 512M

  # Python ingestion service
  liverc-ingestion-service:
    build:
      context: ./ingestion
      dockerfile: Dockerfile
      target: ${INGESTION_BUILD_TARGET:-development}
    container_name: mre-liverc-ingestion-service
    dns:
      - 8.8.8.8
      - 8.8.4.4
      - 1.1.1.1
    dns_search: []
    env_file:
      - .env.docker
    environment:
      # Database connection (connects to existing postgres container)
      DATABASE_URL: postgresql://${POSTGRES_USER:-pacetracer}:${POSTGRES_PASSWORD:-change-me}@mre-postgres:5432/${POSTGRES_DB:-pacetracer}?connection_limit=10&pool_timeout=10
      # Python environment
      PYTHONUNBUFFERED: 1
      LOG_LEVEL: ${LOG_LEVEL:-INFO}
      TZ: ${TZ:-Australia/Sydney}
      # Hot reload for development (set to "true" to enable, "false" or unset for production with workers)
      # When enabled, uses single worker with --reload flag for automatic code reloading
      # When disabled, uses multiple workers for concurrent request handling
      # WARNING: Defaulting to false to prevent single-worker bottlenecks in production-like environments
      # Set UVICORN_RELOAD=true explicitly in .env.docker for development if hot reload is needed
      UVICORN_RELOAD: ${UVICORN_RELOAD:-false}
      # Uvicorn workers (only used when UVICORN_RELOAD is false)
      # Default: 4 workers (handles ~4 concurrent long-running ingestions)
      # Increase for higher concurrency (each worker uses ~100-200MB memory)
      UVICORN_WORKERS: ${UVICORN_WORKERS:-4}
      # Track sync report retention (days)
      TRACK_SYNC_REPORT_RETENTION_DAYS: ${TRACK_SYNC_REPORT_RETENTION_DAYS:-30}
      SITE_POLICY_PATH: ${SITE_POLICY_PATH:-/app/policies/site_policy/policy.json}
    ports:
      - "${INGESTION_PORT:-8000}:8000"
    volumes:
      # Mount source code for hot reload (development)
      - ./ingestion:/app/ingestion
      # Mount reports directory (persists reports on host)
      - ./docs/reports:/app/docs/reports
      # Mount site policy config so ingestion honors shared throttling rules
      - ./policies:/app/policies:ro
    networks:
      - mre-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    deploy:
      resources:
        limits:
          # Maximum memory allocation for Python ingestion service
          # Set to 8G to allow maximum usage for heavy ingestion workloads
          memory: 8G
        reservations:
          # Minimum guaranteed memory
          memory: 256M

networks:
  # Development network (external - created separately to allow postgres container persistence)
  # The network is created manually: docker network create my-race-engineer_mre-network
  mre-network:
    external: true
    name: my-race-engineer_mre-network
